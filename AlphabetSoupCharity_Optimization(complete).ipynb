{"cells":[{"cell_type":"markdown","metadata":{"id":"LYs3IYt_Co0Z"},"source":["## Preprocessing"]},{"cell_type":"code","source":["import pandas as pd, numpy as np, tensorflow as tf, os\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","# Read CSV\n","application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n","\n","# 1.  Drop IDs\n","application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n","\n","# 2.  Log-scale ASK_AMT (skew fix)\n","application_df[\"ASK_AMT\"] = np.log1p(application_df[\"ASK_AMT\"])\n","\n","# 3.  MODERATE rare-bucket cut-offs (back to 500 / 1 000)\n","for col, cutoff in [(\"APPLICATION_TYPE\", 500), (\"CLASSIFICATION\", 1000)]:\n","    rare = application_df[col].value_counts().loc[lambda s: s < cutoff].index\n","    application_df[col] = application_df[col].replace(rare, \"Other\")\n","\n","# 4.  One-hot encode\n","dummies = pd.get_dummies(application_df)\n","\n","y = dummies[\"IS_SUCCESSFUL\"]\n","X = dummies.drop(columns=[\"IS_SUCCESSFUL\"])\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.20, stratify=y, random_state=42\n",")\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled  = scaler.transform(X_test)\n"],"metadata":{"id":"8LS57E7GmQW-","executionInfo":{"status":"ok","timestamp":1746134154225,"user_tz":300,"elapsed":1153,"user":{"displayName":"Cade Deal","userId":"13060050404785204217"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"esCxZD5eCo0d"},"source":["## Compile, Train and Evaluate the Model"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, regularizers\n","\n","input_dim = X_train_scaled.shape[1]\n","\n","nn = tf.keras.Sequential([\n","    layers.Dense(512, activation=\"relu\",\n","                 kernel_initializer=\"he_normal\",\n","                 kernel_regularizer=regularizers.l2(1e-4),\n","                 input_dim=input_dim),\n","    layers.BatchNormalization(),\n","\n","    layers.Dense(256, activation=\"relu\",\n","                 kernel_initializer=\"he_normal\",\n","                 kernel_regularizer=regularizers.l2(1e-4)),\n","    layers.BatchNormalization(),\n","\n","    layers.Dense(128, activation=\"relu\",\n","                 kernel_initializer=\"he_normal\",\n","                 kernel_regularizer=regularizers.l2(1e-4)),\n","\n","    layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","nn.compile(optimizer=tf.keras.optimizers.Adam(5e-4),\n","           loss=\"binary_crossentropy\",\n","           metrics=[\"accuracy\"])\n","\n","nn.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":429},"id":"ie_9IR6tmVgI","executionInfo":{"status":"ok","timestamp":1746134154389,"user_tz":300,"elapsed":154,"user":{"displayName":"Cade Deal","userId":"13060050404785204217"}},"outputId":"6ad0c5e2-5b1f-4f53-d859-f20135847e10"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m22,528\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,528</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m189,953\u001b[0m (742.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">189,953</span> (742.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m188,417\u001b[0m (736.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188,417</span> (736.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import os, math\n","\n","early = EarlyStopping(monitor=\"val_loss\",\n","                      patience=40,            # ↖ give it time\n","                      restore_best_weights=True)\n","\n","os.makedirs(\"checkpoints_opt\", exist_ok=True)\n","ckpt = ModelCheckpoint(\"checkpoints_opt/ep_{epoch:03d}.weights.h5\",\n","                       save_weights_only=True)\n","\n","history = nn.fit(\n","    X_train_scaled, y_train,\n","    validation_data=(X_test_scaled, y_test),\n","    epochs=400,\n","    batch_size=64,            # 32 → 64 stabilises BN stats\n","    callbacks=[early, ckpt],\n","    verbose=2\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BoirRDDOmW0Y","executionInfo":{"status":"ok","timestamp":1746134567321,"user_tz":300,"elapsed":412937,"user":{"displayName":"Cade Deal","userId":"13060050404785204217"}},"outputId":"b1b98249-052c-4578-a7fa-b525b251fef9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","429/429 - 8s - 19ms/step - accuracy: 0.7128 - loss: 0.7661 - val_accuracy: 0.7171 - val_loss: 0.7383\n","Epoch 2/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7237 - loss: 0.7241 - val_accuracy: 0.7169 - val_loss: 0.7168\n","Epoch 3/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7284 - loss: 0.7049 - val_accuracy: 0.7163 - val_loss: 0.7052\n","Epoch 4/400\n","429/429 - 6s - 14ms/step - accuracy: 0.7275 - loss: 0.6932 - val_accuracy: 0.7261 - val_loss: 0.6974\n","Epoch 5/400\n","429/429 - 3s - 8ms/step - accuracy: 0.7305 - loss: 0.6815 - val_accuracy: 0.7223 - val_loss: 0.6821\n","Epoch 6/400\n","429/429 - 6s - 13ms/step - accuracy: 0.7316 - loss: 0.6700 - val_accuracy: 0.7192 - val_loss: 0.6712\n","Epoch 7/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7318 - loss: 0.6606 - val_accuracy: 0.7172 - val_loss: 0.6640\n","Epoch 8/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7345 - loss: 0.6502 - val_accuracy: 0.7200 - val_loss: 0.6524\n","Epoch 9/400\n","429/429 - 6s - 15ms/step - accuracy: 0.7331 - loss: 0.6411 - val_accuracy: 0.7264 - val_loss: 0.6458\n","Epoch 10/400\n","429/429 - 3s - 8ms/step - accuracy: 0.7324 - loss: 0.6324 - val_accuracy: 0.7259 - val_loss: 0.6411\n","Epoch 11/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7335 - loss: 0.6239 - val_accuracy: 0.7233 - val_loss: 0.6332\n","Epoch 12/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7331 - loss: 0.6165 - val_accuracy: 0.7195 - val_loss: 0.6262\n","Epoch 13/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7336 - loss: 0.6088 - val_accuracy: 0.7232 - val_loss: 0.6161\n","Epoch 14/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7351 - loss: 0.6029 - val_accuracy: 0.7242 - val_loss: 0.6094\n","Epoch 15/400\n","429/429 - 6s - 14ms/step - accuracy: 0.7351 - loss: 0.5967 - val_accuracy: 0.7259 - val_loss: 0.6040\n","Epoch 16/400\n","429/429 - 3s - 8ms/step - accuracy: 0.7366 - loss: 0.5916 - val_accuracy: 0.7242 - val_loss: 0.5997\n","Epoch 17/400\n","429/429 - 6s - 14ms/step - accuracy: 0.7347 - loss: 0.5869 - val_accuracy: 0.7243 - val_loss: 0.5948\n","Epoch 18/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7360 - loss: 0.5823 - val_accuracy: 0.7246 - val_loss: 0.5886\n","Epoch 19/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7344 - loss: 0.5792 - val_accuracy: 0.7239 - val_loss: 0.5878\n","Epoch 20/400\n","429/429 - 6s - 14ms/step - accuracy: 0.7347 - loss: 0.5757 - val_accuracy: 0.7249 - val_loss: 0.5814\n","Epoch 21/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7347 - loss: 0.5731 - val_accuracy: 0.7235 - val_loss: 0.5799\n","Epoch 22/400\n","429/429 - 6s - 14ms/step - accuracy: 0.7361 - loss: 0.5697 - val_accuracy: 0.7264 - val_loss: 0.5764\n","Epoch 23/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7378 - loss: 0.5670 - val_accuracy: 0.7265 - val_loss: 0.5761\n","Epoch 24/400\n","429/429 - 3s - 8ms/step - accuracy: 0.7368 - loss: 0.5652 - val_accuracy: 0.7238 - val_loss: 0.5778\n","Epoch 25/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7350 - loss: 0.5642 - val_accuracy: 0.7265 - val_loss: 0.5738\n","Epoch 26/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7345 - loss: 0.5627 - val_accuracy: 0.7238 - val_loss: 0.5712\n","Epoch 27/400\n","429/429 - 5s - 13ms/step - accuracy: 0.7365 - loss: 0.5613 - val_accuracy: 0.7257 - val_loss: 0.5699\n","Epoch 28/400\n","429/429 - 6s - 13ms/step - accuracy: 0.7348 - loss: 0.5606 - val_accuracy: 0.7216 - val_loss: 0.5675\n","Epoch 29/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7358 - loss: 0.5589 - val_accuracy: 0.7255 - val_loss: 0.5706\n","Epoch 30/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7367 - loss: 0.5582 - val_accuracy: 0.7254 - val_loss: 0.5693\n","Epoch 31/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7367 - loss: 0.5572 - val_accuracy: 0.7277 - val_loss: 0.5673\n","Epoch 32/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7357 - loss: 0.5566 - val_accuracy: 0.7232 - val_loss: 0.5667\n","Epoch 33/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7363 - loss: 0.5551 - val_accuracy: 0.7251 - val_loss: 0.5659\n","Epoch 34/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7356 - loss: 0.5552 - val_accuracy: 0.7245 - val_loss: 0.5664\n","Epoch 35/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7368 - loss: 0.5552 - val_accuracy: 0.7257 - val_loss: 0.5655\n","Epoch 36/400\n","429/429 - 6s - 14ms/step - accuracy: 0.7359 - loss: 0.5542 - val_accuracy: 0.7254 - val_loss: 0.5648\n","Epoch 37/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7360 - loss: 0.5532 - val_accuracy: 0.7238 - val_loss: 0.5642\n","Epoch 38/400\n","429/429 - 6s - 14ms/step - accuracy: 0.7385 - loss: 0.5526 - val_accuracy: 0.7265 - val_loss: 0.5629\n","Epoch 39/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7375 - loss: 0.5526 - val_accuracy: 0.7227 - val_loss: 0.5675\n","Epoch 40/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7363 - loss: 0.5529 - val_accuracy: 0.7245 - val_loss: 0.5647\n","Epoch 41/400\n","429/429 - 6s - 15ms/step - accuracy: 0.7364 - loss: 0.5525 - val_accuracy: 0.7198 - val_loss: 0.5656\n","Epoch 42/400\n","429/429 - 3s - 8ms/step - accuracy: 0.7366 - loss: 0.5523 - val_accuracy: 0.7268 - val_loss: 0.5630\n","Epoch 43/400\n","429/429 - 6s - 13ms/step - accuracy: 0.7371 - loss: 0.5518 - val_accuracy: 0.7271 - val_loss: 0.5619\n","Epoch 44/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7371 - loss: 0.5504 - val_accuracy: 0.7243 - val_loss: 0.5624\n","Epoch 45/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7368 - loss: 0.5514 - val_accuracy: 0.7235 - val_loss: 0.5625\n","Epoch 46/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7380 - loss: 0.5503 - val_accuracy: 0.7243 - val_loss: 0.5624\n","Epoch 47/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7378 - loss: 0.5501 - val_accuracy: 0.7258 - val_loss: 0.5665\n","Epoch 48/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7375 - loss: 0.5500 - val_accuracy: 0.7204 - val_loss: 0.5630\n","Epoch 49/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7375 - loss: 0.5502 - val_accuracy: 0.7278 - val_loss: 0.5601\n","Epoch 50/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7390 - loss: 0.5487 - val_accuracy: 0.7222 - val_loss: 0.5644\n","Epoch 51/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7384 - loss: 0.5493 - val_accuracy: 0.7255 - val_loss: 0.5623\n","Epoch 52/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7388 - loss: 0.5489 - val_accuracy: 0.7267 - val_loss: 0.5620\n","Epoch 53/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7383 - loss: 0.5491 - val_accuracy: 0.7211 - val_loss: 0.5638\n","Epoch 54/400\n","429/429 - 3s - 8ms/step - accuracy: 0.7392 - loss: 0.5490 - val_accuracy: 0.7262 - val_loss: 0.5611\n","Epoch 55/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7386 - loss: 0.5481 - val_accuracy: 0.7245 - val_loss: 0.5611\n","Epoch 56/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7400 - loss: 0.5474 - val_accuracy: 0.7254 - val_loss: 0.5621\n","Epoch 57/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7396 - loss: 0.5475 - val_accuracy: 0.7249 - val_loss: 0.5626\n","Epoch 58/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7386 - loss: 0.5477 - val_accuracy: 0.7249 - val_loss: 0.5651\n","Epoch 59/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7382 - loss: 0.5474 - val_accuracy: 0.7229 - val_loss: 0.5640\n","Epoch 60/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7390 - loss: 0.5470 - val_accuracy: 0.7255 - val_loss: 0.5615\n","Epoch 61/400\n","429/429 - 6s - 13ms/step - accuracy: 0.7392 - loss: 0.5466 - val_accuracy: 0.7258 - val_loss: 0.5639\n","Epoch 62/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7392 - loss: 0.5464 - val_accuracy: 0.7267 - val_loss: 0.5614\n","Epoch 63/400\n","429/429 - 3s - 8ms/step - accuracy: 0.7391 - loss: 0.5463 - val_accuracy: 0.7249 - val_loss: 0.5649\n","Epoch 64/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7383 - loss: 0.5463 - val_accuracy: 0.7257 - val_loss: 0.5653\n","Epoch 65/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7399 - loss: 0.5454 - val_accuracy: 0.7264 - val_loss: 0.5638\n","Epoch 66/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7387 - loss: 0.5459 - val_accuracy: 0.7241 - val_loss: 0.5625\n","Epoch 67/400\n","429/429 - 6s - 15ms/step - accuracy: 0.7400 - loss: 0.5455 - val_accuracy: 0.7270 - val_loss: 0.5621\n","Epoch 68/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7399 - loss: 0.5448 - val_accuracy: 0.7243 - val_loss: 0.5654\n","Epoch 69/400\n","429/429 - 6s - 13ms/step - accuracy: 0.7393 - loss: 0.5454 - val_accuracy: 0.7227 - val_loss: 0.5661\n","Epoch 70/400\n","429/429 - 4s - 10ms/step - accuracy: 0.7393 - loss: 0.5455 - val_accuracy: 0.7249 - val_loss: 0.5660\n","Epoch 71/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7403 - loss: 0.5449 - val_accuracy: 0.7236 - val_loss: 0.5632\n","Epoch 72/400\n","429/429 - 6s - 15ms/step - accuracy: 0.7414 - loss: 0.5438 - val_accuracy: 0.7220 - val_loss: 0.5651\n","Epoch 73/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7404 - loss: 0.5441 - val_accuracy: 0.7257 - val_loss: 0.5636\n","Epoch 74/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7402 - loss: 0.5438 - val_accuracy: 0.7243 - val_loss: 0.5619\n","Epoch 75/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7401 - loss: 0.5445 - val_accuracy: 0.7249 - val_loss: 0.5652\n","Epoch 76/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7402 - loss: 0.5445 - val_accuracy: 0.7213 - val_loss: 0.5661\n","Epoch 77/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7399 - loss: 0.5437 - val_accuracy: 0.7259 - val_loss: 0.5678\n","Epoch 78/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7419 - loss: 0.5433 - val_accuracy: 0.7243 - val_loss: 0.5668\n","Epoch 79/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7420 - loss: 0.5431 - val_accuracy: 0.7223 - val_loss: 0.5647\n","Epoch 80/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7420 - loss: 0.5431 - val_accuracy: 0.7242 - val_loss: 0.5634\n","Epoch 81/400\n","429/429 - 6s - 13ms/step - accuracy: 0.7415 - loss: 0.5427 - val_accuracy: 0.7251 - val_loss: 0.5648\n","Epoch 82/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7410 - loss: 0.5431 - val_accuracy: 0.7258 - val_loss: 0.5631\n","Epoch 83/400\n","429/429 - 7s - 15ms/step - accuracy: 0.7406 - loss: 0.5423 - val_accuracy: 0.7226 - val_loss: 0.5663\n","Epoch 84/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7421 - loss: 0.5424 - val_accuracy: 0.7235 - val_loss: 0.5636\n","Epoch 85/400\n","429/429 - 5s - 12ms/step - accuracy: 0.7419 - loss: 0.5422 - val_accuracy: 0.7246 - val_loss: 0.5628\n","Epoch 86/400\n","429/429 - 5s - 13ms/step - accuracy: 0.7421 - loss: 0.5417 - val_accuracy: 0.7239 - val_loss: 0.5672\n","Epoch 87/400\n","429/429 - 4s - 8ms/step - accuracy: 0.7406 - loss: 0.5420 - val_accuracy: 0.7251 - val_loss: 0.5670\n","Epoch 88/400\n","429/429 - 4s - 9ms/step - accuracy: 0.7420 - loss: 0.5417 - val_accuracy: 0.7235 - val_loss: 0.5620\n","Epoch 89/400\n","429/429 - 5s - 11ms/step - accuracy: 0.7413 - loss: 0.5410 - val_accuracy: 0.7255 - val_loss: 0.5637\n"]}]},{"cell_type":"code","source":["loss, acc = nn.evaluate(X_test_scaled, y_test, verbose=0)\n","print(f\"Validation accuracy: {acc:.4%} | loss: {loss:.4f}\")\n","\n","nn.save(\"AlphabetSoupCharity_Optimization.h5\")\n","print(\"Saved model → AlphabetSoupCharity_Optimization.h5\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xr0cDURrmZNz","executionInfo":{"status":"ok","timestamp":1746134753677,"user_tz":300,"elapsed":647,"user":{"displayName":"Cade Deal","userId":"13060050404785204217"}},"outputId":"fa80d0f7-6d9f-43da-9ea7-3b4a72c0a825"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Validation accuracy: 72.7843% | loss: 0.5601\n","Saved model → AlphabetSoupCharity_Optimization.h5\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.-1.-1"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"provenance":[{"file_id":"1Q1pVTALnneQY74FaHjvU9XgUMGBbU-2v","timestamp":1746126797728},{"file_id":"1__RELuYGW7b_75Q9xhvWdo6N9aACwA7h","timestamp":1746123033833}]}},"nbformat":4,"nbformat_minor":0}